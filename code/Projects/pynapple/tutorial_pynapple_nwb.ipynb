{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# NWB & Lazy-loading\n",
        "\n",
        "Pynapple currently provides loaders for two data formats :\n",
        "\n",
        " - `npz` with a special structure. You can check this [notebook](../tutorial_pynapple_io) for a descrition of the methods for saving/loading `npz` files.\n",
        "\n",
        " - [NWB format](https://pynwb.readthedocs.io/en/stable/index.html#)\n",
        "\n",
        "This notebook focuses on the NWB format. Additionaly it demonstrates the capabilities of pynapple for lazy-loading different formats.\n",
        "\n",
        "\n",
        "The dataset in this example can be found [here](https://www.dropbox.com/s/pr1ze1nuiwk8kw9/MyProject.zip?dl=1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pynapple as nap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NWB\n",
        "--------------\n",
        "When loading a NWB file, pynapple will walk through it and test the compatibility of each data structure with a pynapple objects. If the data structure is incompatible, pynapple will ignore it. The class that deals with reading NWB file is [`nap.NWBFile`](../../../reference/io/interface_nwb/). You can pass the path to a NWB file or directly an opened NWB file. Alternatively you can use the function [`nap.load_file`](../../../reference/io/misc/#pynapple.io.misc.load_file).\n",
        "\n",
        "\n",
        "!!! note\n",
        "\tCreating the NWB file is outside the scope of pynapple. The NWB file used here has already been created before.\n",
        "\tMultiple tools exists to create NWB file automatically. You can check [neuroconv](https://neuroconv.readthedocs.io/en/main/), [NWBGuide](https://nwb-guide.readthedocs.io/en/latest/) or even [NWBmatic](https://github.com/pynapple-org/nwbmatic).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\johnj\\anaconda3\\envs\\spellPy\\lib\\site-packages\\pynwb\\base.py:203: UserWarning: IntervalSeries 'lick_times_all_index': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
            "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
            "c:\\Users\\johnj\\anaconda3\\envs\\spellPy\\lib\\site-packages\\pynwb\\base.py:203: UserWarning: IntervalSeries 'lick_times_left_index': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
            "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
            "c:\\Users\\johnj\\anaconda3\\envs\\spellPy\\lib\\site-packages\\pynwb\\base.py:203: UserWarning: IntervalSeries 'lick_times_right_index': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
            "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
            "c:\\Users\\johnj\\anaconda3\\envs\\spellPy\\lib\\site-packages\\pynwb\\base.py:203: UserWarning: IntervalSeries 'reward_time_index': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
            "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
            "c:\\Users\\johnj\\anaconda3\\envs\\spellPy\\lib\\site-packages\\pynwb\\base.py:203: UserWarning: IntervalSeries 'stim_off_times': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
            "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
            "c:\\Users\\johnj\\anaconda3\\envs\\spellPy\\lib\\site-packages\\pynwb\\base.py:203: UserWarning: IntervalSeries 'stim_on_times': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
            "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
            "c:\\Users\\johnj\\anaconda3\\envs\\spellPy\\lib\\site-packages\\pynwb\\base.py:203: UserWarning: IntervalSeries 'trial_end_index': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
            "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n",
            "c:\\Users\\johnj\\anaconda3\\envs\\spellPy\\lib\\site-packages\\pynwb\\base.py:203: UserWarning: IntervalSeries 'trial_start_index': Length of data does not match length of timestamps. Your data may be transposed. Time should be on the 0th dimension\n",
            "  warn(\"%s '%s': Length of data does not match length of timestamps. Your data may be transposed. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "t284_SEDS2_L5\n",
            "┍━━━━━━━━━━━━━━━━━━━━━━━━┯━━━━━━━━━━━━━┑\n",
            "│ Keys                   │ Type        │\n",
            "┝━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━┥\n",
            "│ trials                 │ IntervalSet │\n",
            "│ stim_on                │ IntervalSet │\n",
            "│ stim_off               │ IntervalSet │\n",
            "│ lickR_times            │ IntervalSet │\n",
            "│ lickL_times            │ IntervalSet │\n",
            "│ plane0                 │ TsdFrame    │\n",
            "│ trial_start_index      │ Tsd         │\n",
            "│ trial_end_index        │ Tsd         │\n",
            "│ stim_on_times          │ Tsd         │\n",
            "│ stim_off_times         │ Tsd         │\n",
            "│ reward_time_index      │ Tsd         │\n",
            "│ lick_times_right_index │ Tsd         │\n",
            "│ lick_times_left_index  │ Tsd         │\n",
            "│ lick_times_all_index   │ Tsd         │\n",
            "│ frameTimes             │ Tsd         │\n",
            "│ TwoPhotonSeries        │ TsdTensor   │\n",
            "┕━━━━━━━━━━━━━━━━━━━━━━━━┷━━━━━━━━━━━━━┙\n"
          ]
        }
      ],
      "source": [
        "nwbpath = r\"C:\\Users\\johnj\\SpellmanLab Dropbox\\timspellman\\Python\\John\\PySpell\\code\\Projects\\L6 neurons\\data\\L6L5_MDT_Neurons\\t284_SEDS2_L5.nwb\"\n",
        "data = nap.load_file(nwbpath)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pynapple will give you a table with all the entries of the NWB file that are compatible with a pynapple object.\n",
        "When parsing the NWB file, nothing is loaded. The `NWBFile` keeps track of the position of the data whithin the NWB file with a key. You can see it with the attributes `key_to_id`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'trials': 'd5d2a86b-08f7-4b3f-afc7-b23a33f39a52',\n",
              " 'stim_on': '74586d17-6b08-4bdd-a5e3-491fe49a7fd2',\n",
              " 'stim_off': 'af596d54-0429-4f33-a8d2-cbbb6415d9d2',\n",
              " 'lickR_times': '9c6a673f-ecb6-4f62-8dd8-1718a041f9b1',\n",
              " 'lickL_times': 'e0a0eab2-521c-4aa5-98b8-87e4b523d409',\n",
              " 'plane0': '5d34f39d-ab18-43b6-b248-cd4e536c689e',\n",
              " 'trial_start_index': 'ee5f3700-b387-496a-970c-265913cf0472',\n",
              " 'trial_end_index': 'b0ceff00-8a89-415b-a32c-76ec1e7c8743',\n",
              " 'stim_on_times': '2e03c292-da75-4277-8f6c-30acea3eda98',\n",
              " 'stim_off_times': 'f3ac3593-9a5e-4bb3-9ceb-5042461514c5',\n",
              " 'reward_time_index': '363fcd3d-799f-4250-a84f-53271a0daa3e',\n",
              " 'lick_times_right_index': '46864619-3997-4341-a75e-f82a6ce507e3',\n",
              " 'lick_times_left_index': 'aa25d394-5aef-4719-bd2c-5bc8f03d0aff',\n",
              " 'lick_times_all_index': 'e5a28506-f045-432c-98a2-4c86eb477e8f',\n",
              " 'frameTimes': '3b28bd51-b639-4d95-b99a-00d84ea354cf',\n",
              " 'TwoPhotonSeries': '28b2b1f3-fb09-4ae2-8c7e-a3f005190cfa'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.key_to_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading an entry will get pynapple to read the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time (s)               0         1         2         3         4  ...\n",
            "--------------  --------  --------  --------  --------  --------  -----\n",
            "0.0              0         0        0          0        0         ...\n",
            "0.333333333      7.7396    0        0         25.9739   0         ...\n",
            "0.666666667      0         0        0         39.2141   1.76511   ...\n",
            "1.0              1.11059   0        0         52.7525   3.51485   ...\n",
            "1.333333333      0         0        0         28.2423   4.3635    ...\n",
            "1.666666667     15.9758    0        0         66.9175   0         ...\n",
            "2.0              0         0        0          8.83468  1.07802   ...\n",
            "...\n",
            "5143.333333333   1.71687  14.6145   0.207691   0        0         ...\n",
            "5143.666666667   4.01754   8.67237  0          0        0         ...\n",
            "5144.0           4.98244  19.1965   0          0        0         ...\n",
            "5144.333333333   0         1.57993  0          0        0         ...\n",
            "5144.666666667   0         3.1182   0          0        0         ...\n",
            "5145.0          10.0118    5.13229  0          0        0         ...\n",
            "5145.333333333  10.4222    3.44069  0          0        0.475147  ...\n",
            "dtype: float32, shape: (15437, 142)\n"
          ]
        }
      ],
      "source": [
        "z = data['plane0']\n",
        "\n",
        "print(data['plane0'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Internally, the `NWBClass` has replaced the pointer to the data with the actual data.\n",
        "\n",
        "While it looks like pynapple has loaded the data, in fact it did not. By default, calling the NWB object will return an HDF5 dataset.\n",
        "!!! warning\n",
        "\n",
        "    New in `0.6.6`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'h5py._hl.dataset.Dataset'>\n"
          ]
        }
      ],
      "source": [
        "print(type(z.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the time array is always loaded.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(z.index.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is very useful in the case of large dataset that do not fit in memory. You can then get a chunk of the data that will actually be loaded.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time (s)              0         1          2         3          4  ...\n",
            "-------------  --------  --------  ---------  --------  ---------  -----\n",
            "670.0           7.63831  0           0        0         0          ...\n",
            "670.333333333   1.34443  0           3.71392  6.01309   2.19196    ...\n",
            "670.666666667  15.4647   0          33.4055   4.95288   1.68306    ...\n",
            "671.0          13.0805   0          59.0301   2.92452   0.108108   ...\n",
            "671.333333333   0        0          59.3639   1.12398   0.661218   ...\n",
            "671.666666667  17.956    0          98.369    6.91388   1.86116    ...\n",
            "672.0           9.83782  0         115.631    6.77676   0.0214209  ...\n",
            "...\n",
            "678.0           0        0          43.1308   0         1.65073    ...\n",
            "678.333333333   0        0          44.2613   5.78649   0          ...\n",
            "678.666666667   0        0           8.59817  0         4.37338    ...\n",
            "679.0           0        0.585392   45.9245   0.356916  0          ...\n",
            "679.333333333   0        1.57036    29.9531   0         0          ...\n",
            "679.666666667   0        0          26.0383   0         0          ...\n",
            "680.0           0        1.16109    25.3545   0         0.420969   ...\n",
            "dtype: float32, shape: (31, 142)\n"
          ]
        }
      ],
      "source": [
        "z_chunk = z.get(670, 680) # getting 10s of data.\n",
        "\n",
        "print(z_chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data are now loaded.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(z_chunk.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can still apply any high level function of pynapple. For example here, we compute some tuning curves without preloading the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\johnj\\AppData\\Local\\Temp\\ipykernel_12004\\2573320140.py:1: UserWarning: Failed to build Tsd.\n",
            " Returning the NWB object for manual inspection\n",
            "  tc = nap.compute_1d_tuning_curves(data['plane0'], data['trial_start_index'], 10)\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "group should be a TsGroup.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tc \u001b[38;5;241m=\u001b[39m \u001b[43mnap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_1d_tuning_curves\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplane0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrial_start_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tc)\n",
            "File \u001b[1;32mc:\\Users\\johnj\\anaconda3\\envs\\spellPy\\lib\\site-packages\\pynapple\\process\\tuning_curves.py:106\u001b[0m, in \u001b[0;36mcompute_1d_tuning_curves\u001b[1;34m(group, feature, nb_bins, ep, minmax)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_1d_tuning_curves\u001b[39m(group, feature, nb_bins, ep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, minmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    Computes 1-dimensional tuning curves relative to a 1d feature.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(group, nap\u001b[38;5;241m.\u001b[39mTsGroup), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup should be a TsGroup.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    108\u001b[0m         feature, (nap\u001b[38;5;241m.\u001b[39mTsd, nap\u001b[38;5;241m.\u001b[39mTsdFrame)\n\u001b[0;32m    109\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature should be a Tsd (or TsdFrame with 1 column only)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature, nap\u001b[38;5;241m.\u001b[39mTsdFrame):\n",
            "\u001b[1;31mAssertionError\u001b[0m: group should be a TsGroup."
          ]
        }
      ],
      "source": [
        "tc = nap.compute_1d_tuning_curves(data['plane0'], data['trial_start_index'], 10)\n",
        "\n",
        "print(tc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! warning\n",
        "    Carefulness should still apply when calling any pynapple function on a memory map. Pynapple does not implement any batching function internally. Calling a high level function of pynapple on a dataset that do not fit in memory will likely cause a memory error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To change this behavior, you can pass `lazy_loading=False` when instantiating the `NWBClass`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "path = \"../../your/path/to/MyProject/sub-A2929/A2929-200711/pynapplenwb/A2929-200711.nwb\"\n",
        "data = nap.NWBFile(path, lazy_loading=False)\n",
        "\n",
        "z = data['z']\n",
        "\n",
        "print(type(z.d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Numpy memory map\n",
        "----------------\n",
        "\n",
        "In fact, pynapple can work with any type of memory map. Here we read a binary file with [`np.memmap`](https://numpy.org/doc/stable/reference/generated/numpy.memmap.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eeg_path = \"../../your/path/to/MyProject/sub-A2929/A2929-200711/A2929-200711.eeg\"\n",
        "frequency = 1250 # Hz\n",
        "n_channels = 16\n",
        "f = open(eeg_path, 'rb') \n",
        "startoffile = f.seek(0, 0)\n",
        "endoffile = f.seek(0, 2)\n",
        "f.close()\n",
        "bytes_size = 2\n",
        "n_samples = int((endoffile-startoffile)/n_channels/bytes_size)\n",
        "duration = n_samples/frequency\n",
        "interval = 1/frequency\n",
        "\n",
        "fp = np.memmap(eeg_path, np.int16, 'r', shape = (n_samples, n_channels))\n",
        "timestep = np.arange(0, n_samples)/frequency\n",
        "\n",
        "print(type(fp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instantiating a pynapple `TsdFrame` will keep the data as a memory map.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "eeg = nap.TsdFrame(t=timestep, d=fp)\n",
        "\n",
        "print(eeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check the type of `eeg.values`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(type(eeg.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Zarr\n",
        "--------------\n",
        "\n",
        "It is also possible to use Higher level library like [zarr](https://zarr.readthedocs.io/en/stable/index.html) also not directly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import zarr\n",
        "data = zarr.zeros((10000, 5), chunks=(1000, 5), dtype='i4')\n",
        "timestep = np.arange(len(data))\n",
        "\n",
        "tsdframe = nap.TsdFrame(t=timestep, d=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the warning suggest, `data` is converted to numpy array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(type(tsdframe.d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To maintain a zarr array, you can change the argument `load_array` to False.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tsdframe = nap.TsdFrame(t=timestep, d=data, load_array=False)\n",
        "\n",
        "print(type(tsdframe.d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Within pynapple, numpy memory map are recognized as numpy array while zarr array are not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(type(fp), \"Is np.ndarray? \", isinstance(fp, np.ndarray))\n",
        "print(type(data), \"Is np.ndarray? \", isinstance(data, np.ndarray))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar to numpy memory map, you can use pynapple functions directly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ep = nap.IntervalSet(0, 10)\n",
        "tsdframe.restrict(ep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "group = nap.TsGroup({0:nap.Ts(t=[10, 20, 30])})\n",
        "\n",
        "sta = nap.compute_event_trigger_average(group, tsdframe, 1, (-2, 3))\n",
        "\n",
        "print(type(tsdframe.values))\n",
        "print(\"\\n\")\n",
        "print(sta)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
